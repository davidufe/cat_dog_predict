{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ATIVIDADE 3 - NAIVES BAYES**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta atividade, devemos anotar a acurácia utiliando os algoritmos `MultinomialNB`, `GaussianNB` e `ComplementNB`, para as mesmas bases de dados que utilizamos nas atividades anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.Importando as Bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.Importando as Bases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_128_16 = pd.read_csv('../datasets/hog_128_16.csv')\n",
    "hog_128_20 = pd.read_csv('../datasets/hog_128_20.csv')\n",
    "cnn_VGG16_AVG_128 = pd.read_csv('../datasets/cnn_VGG16_AVG_128.csv')\n",
    "cnn_VGG19_AVG_128 = pd.read_csv('../datasets/cnn_VGG19_AVG_128.csv')\n",
    "cnn_VGG16_MAX_128 = pd.read_csv('../datasets/cnn_VGG16_MAX_128.csv')\n",
    "cnn_VGG19_MAX_128 = pd.read_csv('../datasets/cnn_VGG19_MAX_128.csv')\n",
    "hog_128_16_PCA = pd.read_csv('../datasets/hog_128_16_PCA.csv')\n",
    "hog_128_20_PCA = pd.read_csv('../datasets/hog_128_20_PCA.csv')\n",
    "cnn_VGG16_AVG_128_PCA = pd.read_csv('../datasets/cnn_VGG16_AVG_128_PCA.csv')\n",
    "cnn_VGG19_AVG_128_PCA= pd.read_csv('../datasets/cnn_VGG19_AVG_128_PCA.csv')\n",
    "cnn_VGG16_MAX_128_PCA= pd.read_csv('../datasets/cnn_VGG16_MAX_128_PCA.csv')\n",
    "cnn_VGG19_MAX_128_PCA = pd.read_csv('../datasets/cnn_VGG19_MAX_128_PCA.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.Códigos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.Instanciando Dict com Todos os DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta estapa serve para conseguirmos passar o nome do dataset na hora de criarmos o DataFrame com as acurácias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'hog_128_16': hog_128_16,\n",
    "    'hog_128_20': hog_128_20,\n",
    "    'cnn_VGG16_AVG_128': cnn_VGG16_AVG_128,\n",
    "    'cnn_VGG19_AVG_128': cnn_VGG19_AVG_128,\n",
    "    'cnn_VGG16_MAX_128': cnn_VGG16_MAX_128,\n",
    "    'cnn_VGG19_MAX_128': cnn_VGG19_MAX_128,\n",
    "    'hog_128_16_PCA': hog_128_16_PCA,\n",
    "    'hog_128_20_PCA': hog_128_20_PCA,\n",
    "    'cnn_VGG16_AVG_128_PCA': cnn_VGG16_AVG_128_PCA,\n",
    "    'cnn_VGG19_AVG_128_PCA': cnn_VGG19_AVG_128_PCA,\n",
    "    'cnn_VGG16_MAX_128_PCA': cnn_VGG16_MAX_128_PCA,\n",
    "    'cnn_VGG19_MAX_128_PCA': cnn_VGG19_MAX_128_PCA\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.Configuração do Dataframe das Acurácias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index = []\n",
    "for name in dataframes.keys():\n",
    "    multi_index.extend([(name, '70/30'), (name, '10-fold CV')])\n",
    "accuracy_df = pd.DataFrame(index=pd.MultiIndex.from_tuples(multi_index), \n",
    "                           columns=['GaussianNB', 'MultinomialNB', 'ComplementNB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.Inicializando os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'GaussianNB': GaussianNB(priors=None, var_smoothing=1e-09),\n",
    "    'MultinomialNB': MultinomialNB(fit_prior=True, alpha=1.0),\n",
    "    'ComplementNB': ComplementNB(alpha=1.0, force_alpha=True, fit_prior=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo que teremos que fazer é normalizar os dados das bases com PCA, pois tanto o MultinomialNB e ComplementNB não funcionam com valores negativos. Normalizando, iremos manter a distribuição dos dados mas iremos setar seus valores com base na média igual a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop que irá realizar para cada uma das bases:\n",
    "* Divisão holdout 70/30 e k-fold (k=10)\n",
    "* Treinamento para todos os modelos\n",
    "* Avaliação para as repectivas base de testes\n",
    "* Salva a suas respectivas acurácias no DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dataset: hog_128_16\n",
      "Normalização aplicada para MultinomialNB no dataset hog_128_16.\n",
      "Normalização aplicada para ComplementNB no dataset hog_128_16.\n",
      "Processando dataset: hog_128_20\n",
      "Normalização aplicada para MultinomialNB no dataset hog_128_20.\n",
      "Normalização aplicada para ComplementNB no dataset hog_128_20.\n",
      "Processando dataset: cnn_VGG16_AVG_128\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG16_AVG_128.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG16_AVG_128.\n",
      "Processando dataset: cnn_VGG19_AVG_128\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG19_AVG_128.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG19_AVG_128.\n",
      "Processando dataset: cnn_VGG16_MAX_128\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG16_MAX_128.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG16_MAX_128.\n",
      "Processando dataset: cnn_VGG19_MAX_128\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG19_MAX_128.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG19_MAX_128.\n",
      "Processando dataset: hog_128_16_PCA\n",
      "Normalização aplicada para MultinomialNB no dataset hog_128_16_PCA.\n",
      "Normalização aplicada para ComplementNB no dataset hog_128_16_PCA.\n",
      "Processando dataset: hog_128_20_PCA\n",
      "Normalização aplicada para MultinomialNB no dataset hog_128_20_PCA.\n",
      "Normalização aplicada para ComplementNB no dataset hog_128_20_PCA.\n",
      "Processando dataset: cnn_VGG16_AVG_128_PCA\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG16_AVG_128_PCA.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG16_AVG_128_PCA.\n",
      "Processando dataset: cnn_VGG19_AVG_128_PCA\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG19_AVG_128_PCA.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG19_AVG_128_PCA.\n",
      "Processando dataset: cnn_VGG16_MAX_128_PCA\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG16_MAX_128_PCA.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG16_MAX_128_PCA.\n",
      "Processando dataset: cnn_VGG19_MAX_128_PCA\n",
      "Normalização aplicada para MultinomialNB no dataset cnn_VGG19_MAX_128_PCA.\n",
      "Normalização aplicada para ComplementNB no dataset cnn_VGG19_MAX_128_PCA.\n"
     ]
    }
   ],
   "source": [
    "# Loop para processar cada dataset\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"Processando dataset: {name}\")\n",
    "    \n",
    "    X = df.iloc[:, 1:]  # Features\n",
    "    y = df.iloc[:, 0]   # Target\n",
    "    \n",
    "    # Verificar valores negativos no dataset\n",
    "    contains_negatives = (X < 0).any().any()\n",
    "    \n",
    "    # Holdout 70/30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    holdout_accuracies = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Tratamento para MultinomialNB e ComplementNB com valores negativos\n",
    "        if model_name in ['MultinomialNB', 'ComplementNB']:\n",
    "            # Normalizar para garantir compatibilidade\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            print(f\"Normalização aplicada para {model_name} no dataset {name}.\")\n",
    "        \n",
    "        # Treinamento do modelo\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            holdout_accuracies[model_name] = acc\n",
    "        except ValueError as e:\n",
    "            print(f\"Erro ao treinar {model_name} no dataset {name}: {e}\")\n",
    "            holdout_accuracies[model_name] = np.nan\n",
    "    \n",
    "    # Salvando os resultados do Holdout\n",
    "    for model_name, acc in holdout_accuracies.items():\n",
    "        accuracy_df.loc[(name, '70/30'), model_name] = acc\n",
    "    \n",
    "    # KFold com k=10\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    kfold_accuracies = {model_name: [] for model_name in models.keys()}\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            # Tratamento para MultinomialNB e ComplementNB com valores negativos\n",
    "            if model_name in ['MultinomialNB', 'ComplementNB']:\n",
    "                # Normalizar para garantir compatibilidade\n",
    "                scaler = MinMaxScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # Treinamento do modelo\n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                kfold_accuracies[model_name].append(acc)\n",
    "            except ValueError as e:\n",
    "                print(f\"Erro ao treinar {model_name} no dataset {name} (KFold): {e}\")\n",
    "                kfold_accuracies[model_name].append(np.nan)\n",
    "    \n",
    "    # Calculando a média das acurácias do KFold\n",
    "    for model_name, acc_list in kfold_accuracies.items():\n",
    "        if acc_list:  # Garantir que não seja vazio (caso MultinomialNB ou ComplementNB tenha sido ignorado)\n",
    "            accuracy_df.loc[(name, '10-fold CV'), model_name] = np.nanmean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>ComplementNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hog_128_16</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.676614</td>\n",
       "      <td>0.645538</td>\n",
       "      <td>0.646788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hog_128_20</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.665491</td>\n",
       "      <td>0.646772</td>\n",
       "      <td>0.646772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG16_AVG_128</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.508687</td>\n",
       "      <td>0.622785</td>\n",
       "      <td>0.631551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG19_AVG_128</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.521218</td>\n",
       "      <td>0.601566</td>\n",
       "      <td>0.606535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG16_MAX_128</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.506203</td>\n",
       "      <td>0.621472</td>\n",
       "      <td>0.626487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG19_MAX_128</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.521282</td>\n",
       "      <td>0.599051</td>\n",
       "      <td>0.615316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hog_128_16_PCA</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.620833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.651756</td>\n",
       "      <td>0.618038</td>\n",
       "      <td>0.650554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hog_128_20_PCA</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.635459</td>\n",
       "      <td>0.602943</td>\n",
       "      <td>0.635443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG16_AVG_128_PCA</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.579167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.561313</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.621535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG19_AVG_128_PCA</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.579167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.590158</td>\n",
       "      <td>0.530206</td>\n",
       "      <td>0.602785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG16_MAX_128_PCA</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.54625</td>\n",
       "      <td>0.536535</td>\n",
       "      <td>0.600237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn_VGG19_MAX_128_PCA</th>\n",
       "      <th>70/30</th>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.554167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-fold CV</th>\n",
       "      <td>0.557595</td>\n",
       "      <td>0.511345</td>\n",
       "      <td>0.565222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 GaussianNB MultinomialNB ComplementNB\n",
       "hog_128_16            70/30        0.658333      0.645833     0.645833\n",
       "                      10-fold CV   0.676614      0.645538     0.646788\n",
       "hog_128_20            70/30        0.683333      0.641667     0.645833\n",
       "                      10-fold CV   0.665491      0.646772     0.646772\n",
       "cnn_VGG16_AVG_128     70/30        0.495833      0.583333       0.5875\n",
       "                      10-fold CV   0.508687      0.622785     0.631551\n",
       "cnn_VGG19_AVG_128     70/30        0.483333      0.579167     0.566667\n",
       "                      10-fold CV   0.521218      0.601566     0.606535\n",
       "cnn_VGG16_MAX_128     70/30        0.495833      0.604167          0.6\n",
       "                      10-fold CV   0.506203      0.621472     0.626487\n",
       "cnn_VGG19_MAX_128     70/30        0.479167      0.504167       0.5625\n",
       "                      10-fold CV   0.521282      0.599051     0.615316\n",
       "hog_128_16_PCA        70/30            0.65        0.5625     0.620833\n",
       "                      10-fold CV   0.651756      0.618038     0.650554\n",
       "hog_128_20_PCA        70/30        0.641667        0.5875         0.65\n",
       "                      10-fold CV   0.635459      0.602943     0.635443\n",
       "cnn_VGG16_AVG_128_PCA 70/30          0.5875          0.55     0.579167\n",
       "                      10-fold CV   0.561313      0.587785     0.621535\n",
       "cnn_VGG19_AVG_128_PCA 70/30          0.5375      0.479167     0.579167\n",
       "                      10-fold CV   0.590158      0.530206     0.602785\n",
       "cnn_VGG16_MAX_128_PCA 70/30          0.5375      0.541667     0.541667\n",
       "                      10-fold CV    0.54625      0.536535     0.600237\n",
       "cnn_VGG19_MAX_128_PCA 70/30        0.508333      0.483333     0.554167\n",
       "                      10-fold CV   0.557595      0.511345     0.565222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.Salvando em Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo como 'acuracias_naive_bayes.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "arquivo_excel = \"acuracias_naive_bayes.xlsx\"\n",
    "accuracy_df.to_excel(arquivo_excel, sheet_name=\"Acurácias\")\n",
    "print(f\"Arquivo salvo como '{arquivo_excel}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.Conclusões**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O melhor método foi o ComplementNB.\n",
    "* Todas as bases PCA foram piores do que as suas versões originais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
